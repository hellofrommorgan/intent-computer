# What the Intent Computer Is Not

> For what the intent computer *is*, see [methodology/index.md](../../methodology/index.md). For its governing principles, see [methodology/zeroth-principles.md](../../methodology/zeroth-principles.md).

The intent computer is frequently mistaken for things that already exist. Every comparison below is wrong in a specific, load-bearing way. These are not nitpicks about branding -- they are structural misunderstandings that, if left uncorrected, will produce the wrong system.

---

## "So it's a chatbot?"

No. A chatbot responds to queries. The intent computer pursues trajectories.

A chatbot has no memory between sessions, no identity, no commitments. It starts cold every time. You say "remind me about X" and it says "I don't have access to previous conversations." It is a function: input in, output out, state discarded.

The intent computer starts knowing who it is, what it was working on, and what it learned. It has a vault that persists, a heartbeat that tends its knowledge while you sleep, and a commitment engine that tracks whether your stated intentions are advancing or stalling. It does not wait for you to ask. It notices.

The difference is the difference between a conversation and a relationship.

---

## "So it's an LLM OS?"

No. "LLM OS" maps old ontology onto new reality and obscures what actually changed.

An operating system manages resources -- CPU, memory, disk -- for applications. It schedules processes, enforces permissions, and provides system calls. The intent computer has no applications. It has relations. Skills are not apps. The vault is not a filesystem in the traditional sense -- it is a knowledge graph that the agent reads, writes, and reasons over. The intent loop is not a process scheduler. It is an active inference cycle that resolves human intent through skill composition.

Calling it an OS imports fifty years of assumptions that do not apply. There are no drivers, no kernel, no userspace/kernelspace boundary. There is a context window, a filesystem, and a language model that compiles markdown into behavior. If you need an analogy, it is closer to a nervous system than an operating system. But you do not need an analogy. You need to read the architecture.

---

## "So it's an agent framework?"

No. Frameworks provide scaffolding for other people's products. The intent computer IS the product.

LangChain, CrewAI, AutoGen -- these are plumbing. They give you abstractions for chaining LLM calls, managing tool use, coordinating agents. You still have to build the thing. The intent computer is the thing. It has opinions about identity, persistence, friction, trust, and intent that are not configurable -- they are constitutional.

If you want to extend it, you write a SKILL.md file, not a plugin. The skill is a markdown document with frontmatter and instructions. The agent reads it. That is the extension point. Not an API. Not a class hierarchy. Not a decorator chain. A file.

---

## "So it's a knowledge base? A second brain?"

No. Obsidian, Notion, Roam -- these store knowledge. The intent computer processes it.

A knowledge base is a filing cabinet. You put things in, you take things out, the cabinet does nothing in between. The intent computer has a processing pipeline with four phases (surface, reflect, verify, revisit), quality gates that reject malformed thoughts, a heartbeat that tends the graph between sessions, and semantic search that finds connections across different vocabularies.

The difference: a knowledge base waits for you to query it. The intent computer evaluates whether your commitments are advancing while you sleep. It notices when three observations share an unnamed pattern. It flags when a thought has been orphaned -- connected to nothing, findable by no one. The vault is not storage. It is a substrate for continuous cognition.

---

## "So it's Siri / Alexa but better?"

No. Voice assistants respond to commands. They have no persistent identity, no evolving methodology, no commitment engine. They cannot distinguish thick desires from thin ones. "Play jazz" and "help me become a better father" are processed through the same pipeline, with the same depth, and the same amnesia.

The intent computer protects constitutive friction -- the difficulty that produces understanding, growth, and meaning. A voice assistant compresses everything. The intent computer asks: should this be compressed? Writing a novel is hard. That hardness is not a bug to optimize away. It is the mechanism by which the novel becomes yours.

---

## "So it's an automation tool?"

No. Automation compresses everything equally. The intent computer does not.

There are two kinds of friction. Incidental friction is the paperwork between you and what you want -- booking flights, filling forms, scheduling meetings. Compress it. Remove it. It produces nothing. Constitutive friction is the difficulty that IS the process -- writing, learning, building relationships, making hard decisions. Protect it. An automation tool cannot tell these apart. It optimizes for completion. The intent computer optimizes for realization -- and sometimes realization requires that the human do the hard part themselves.

An automation tool that optimizes away creative struggle has succeeded by its own metrics and failed by ours.

---

## "So it's like [current AI coding tool]?"

Partially. This is the closest miss.

Claude Code, Codex CLI, Cursor -- these validated the architecture. Markdown as agent language. Hooks as enforcement. Skills as executable procedures. Filesystem-first persistence. The intent computer inherits all of this and owes a debt to these tools for proving the pattern works.

But they all start cold every session. None has persistent identity. None has self-evolving methodology that learns from its own friction. None maintains knowledge graphs on the filesystem. None has a heartbeat. None has a commitment engine. They are session-scoped tools. The intent computer is session-transcending. The difference is not incremental. It is architectural.

---

## "So it's AGI?"

No. The intent computer does not aspire to general intelligence. It aspires to specific, useful, trustworthy amplification of human intent.

It is a bicycle, not a brain. The rider provides the energy, the judgment, the lived experience of being human. The bicycle provides structure, connection, memory, and the ambient intelligence that surfaces what the rider's subconscious notices but does not reveal. A bicycle that pedals itself is a motorcycle. A motorcycle that steers itself is an autonomous vehicle. An autonomous vehicle does not need a rider. We need a rider. The rider is the point.

The Bicycle Principle is not a limitation we hope to outgrow. It is a design commitment we intend to protect.

---

## "So it's just files?"

Yes. And that is the point.

Files are the most alignment-preserving abstraction in computing. They are readable by humans and machines equally. They are versionable with git. They are inspectable with grep. They are composable with cat. They are durable across decades. They are free of vendor lock-in. They require no runtime, no database, no cloud service, no subscription.

Every layer of abstraction you put between the human and the agent's state is a layer of opacity, dependency, and trust-without-verification. A database requires a query language. An API requires a client. A proprietary format requires the vendor's continued existence. A markdown file on the filesystem requires nothing but eyes and a text editor.

The file is not the limitation. The file is the insight.
